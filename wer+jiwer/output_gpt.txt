ðŸš€ Starting WER processing for all calls in: /Users/adyasrivastava/wer/wer+jiwer/calls
================================================================================
ðŸš€ [03261666-7d82-49ec-8d6e-78c2f716ad73] started at 19:11:13
ðŸŽ¯ Filtered 17 assistant utterances from 31 total utterances
ðŸŽ¯ Filtered 13 Agent utterances from 23 total utterances
Sending transcripts to LLM in parallel...
âŒ [03261666-7d82-49ec-8d6e-78c2f716ad73] failed: Extra data: line 25 column 2 (char 465)
âŒ [03261666-7d82-49ec-8d6e-78c2f716ad73] failed: Extra data: line 25 column 2 (char 465)
ðŸš€ [03856e6b-6925-4012-8eb8-0a0289019b7e] started at 19:11:40
ðŸŽ¯ Filtered 21 assistant utterances from 41 total utterances
ðŸŽ¯ Filtered 13 Agent utterances from 26 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/03856e6b-6925-4012-8eb8-0a0289019b7e/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/03856e6b-6925-4012-8eb8-0a0289019b7e/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 77 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/03856e6b-6925-4012-8eb8-0a0289019b7e/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/03856e6b-6925-4012-8eb8-0a0289019b7e/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.1829
  Total GT NERs: 26
  Total Ref NERs: 29
  Unique GT NERs: 17
  Unique Ref NERs: 25
  Total Concerned GT NERs (PERSON/ORG): 12
  Total Concerned Ref NERs (PERSON/ORG): 14
  Unique Concerned GT NERs: 5
  Unique Concerned Ref NERs: 10
  Time taken: 0.820299 seconds

  Substitutions:
  Deletions:
    1. 'hello' â€” missing in hypothesis
    2. 'this' â€” missing in hypothesis
    3. 'is' â€” missing in hypothesis
    4. 'priya' â€” missing in hypothesis
    5. 'hello' â€” missing in hypothesis
    6. 'this' â€” missing in hypothesis
    7. 'is' â€” missing in hypothesis
    8. 'priya' â€” missing in hypothesis
    9. 'from' â€” missing in hypothesis
    10. 'elevate' â€” missing in hypothesis
    11. 'now' â€” missing in hypothesis
    12. 'hello' â€” missing in hypothesis
    13. 'this' â€” missing in hypothesis
    14. 'is' â€” missing in hypothesis
    15. 'priya' â€” missing in hypothesis
    16. 'from' â€” missing in hypothesis
    17. 'elevate' â€” missing in hypothesis
    18. 'now' â€” missing in hypothesis
    19. 'am' â€” missing in hypothesis
    20. 'i' â€” missing in hypothesis
    21. 'speaking' â€” missing in hypothesis
    22. 'with' â€” missing in hypothesis
    23. 'atul' â€” missing in hypothesis
    24. 'sinha' â€” missing in hypothesis
    25. 'now' â€” missing in hypothesis
    26. 'now's' â€” missing in hypothesis
    27. 'ai' â€” missing in hypothesis
  Insertions:
    1. 'are' â€” extra in hypothesis
    2. 'we' â€” extra in hypothesis
    3. 'are' â€” extra in hypothesis
    4. 'serviceable' â€” extra in hypothesis
    5. 'for' â€” extra in hypothesis
    6. 'most' â€” extra in hypothesis
    7. 'parts' â€” extra in hypothesis
    8. 'of' â€” extra in hypothesis
    9. 'india' â€” extra in hypothesis
    10. 'including' â€” extra in hypothesis
    11. 'patna' â€” extra in hypothesis
    12. 'as' â€” extra in hypothesis
    13. 'we' â€” extra in hypothesis
    14. 'have' â€” extra in hypothesis
    15. 'partnered' â€” extra in hypothesis
    16. 'with' â€” extra in hypothesis
    17. 'several' â€” extra in hypothesis
    18. 'lab' â€” extra in hypothesis
    19. 'test' â€” extra in hypothesis
    20. 'providers' â€” extra in hypothesis
    21. 'you' â€” extra in hypothesis
    22. 'can' â€” extra in hypothesis
    23. 'definitely' â€” extra in hypothesis
    24. 'access' â€” extra in hypothesis
    25. 'the' â€” extra in hypothesis
    26. 'nano' â€” extra in hypothesis
    27. 'plan' â€” extra in hypothesis
    28. 'there' â€” extra in hypothesis
    29. 'would' â€” extra in hypothesis
    30. 'you' â€” extra in hypothesis
    31. 'like' â€” extra in hypothesis
    32. 'to' â€” extra in hypothesis
    33. 'know' â€” extra in hypothesis
    34. 'more' â€” extra in hypothesis
    35. 'about' â€” extra in hypothesis
    36. 'how' â€” extra in hypothesis
    37. 'it' â€” extra in hypothesis
    38. 'can' â€” extra in hypothesis
    39. 'help' â€” extra in hypothesis
    40. 'you' â€” extra in hypothesis
    41. 'achieve' â€” extra in hypothesis
    42. 'weight' â€” extra in hypothesis
    43. 'loss' â€” extra in hypothesis
    44. 'goals' â€” extra in hypothesis
    45. 'our' â€” extra in hypothesis
    46. 'endocrinology' â€” extra in hypothesis
    47. 'diabetes' â€” extra in hypothesis
    48. 'partial' â€” extra in hypothesis
    49. 'or' â€” extra in hypothesis
    50. 'full' â€” extra in hypothesis
ðŸ [03856e6b-6925-4012-8eb8-0a0289019b7e] completed at 19:12:21, took 40.76s
ðŸš€ [09f69426-e7e6-4f2a-a20a-75416d945306] started at 19:12:21
ðŸŽ¯ Filtered 27 assistant utterances from 51 total utterances
ðŸŽ¯ Filtered 23 Agent utterances from 34 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/09f69426-e7e6-4f2a-a20a-75416d945306/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/09f69426-e7e6-4f2a-a20a-75416d945306/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 89 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/09f69426-e7e6-4f2a-a20a-75416d945306/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/09f69426-e7e6-4f2a-a20a-75416d945306/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.1252
  Total GT NERs: 42
  Total Ref NERs: 42
  Unique GT NERs: 23
  Unique Ref NERs: 21
  Total Concerned GT NERs (PERSON/ORG): 37
  Total Concerned Ref NERs (PERSON/ORG): 33
  Unique Concerned GT NERs: 18
  Unique Concerned Ref NERs: 14
  Time taken: 2.139239 seconds

  Substitutions:
    1. 'you' -> 'great'
    2. 'id' -> 'i'd'
    3. '1799' -> 'ninetynine'
    4. 'hai' -> 'hain'
    5. 'sevaon' -> 'sevao'
    6. '1799' -> 'hundred'
    7. 'rupaye' -> 'ninetynine'
    8. 'kya' -> 'is'
    9. 'ya' -> 'aur'
    10. 'hai' -> 'hain'
    11. 'sevaon' -> 'sevao'
    12. '6000' -> 'six'
    13. 'rupaye' -> 'thousand'
    14. 'jante' -> 'ke'
    15. 'hain' -> 'bare'
    16. 'aur' -> 'mein'
    17. 'start' -> 'kickstart'
    18. 'map' -> 'roadmap'
    19. 'back' -> 'moneyback'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. 'i' â€” missing in hypothesis
    3. 'noticed' â€” missing in hypothesis
    4. 'kick' â€” missing in hypothesis
    5. '12' â€” missing in hypothesis
    6. 'road' â€” missing in hypothesis
    7. '12' â€” missing in hypothesis
    8. 'money' â€” missing in hypothesis
    9. 'the' â€” missing in hypothesis
    10. 'three' â€” missing in hypothesis
    11. 'months' â€” missing in hypothesis
    12. 'vibhinn' â€” missing in hypothesis
    13. 'vikalp' â€” missing in hypothesis
    14. 'kya' â€” missing in hypothesis
    15. 'aap' â€” missing in hypothesis
    16. 'mujhse' â€” missing in hypothesis
    17. 'nano' â€” missing in hypothesis
    18. 'plan' â€” missing in hypothesis
    19. 'ya' â€” missing in hypothesis
    20. 'uske' â€” missing in hypothesis
    21. 'kisi' â€” missing in hypothesis
    22. 'features' â€” missing in hypothesis
    23. 'ke' â€” missing in hypothesis
    24. 'bare' â€” missing in hypothesis
    25. 'mein' â€” missing in hypothesis
    26. 'janna' â€” missing in hypothesis
    27. 'chahenge' â€” missing in hypothesis
  Insertions:
    1. 'weight' â€” extra in hypothesis
    2. 'ki' â€” extra in hypothesis
    3. 'upfront' â€” extra in hypothesis
    4. 'individually' â€” extra in hypothesis
    5. 'the' â€” extra in hypothesis
    6. 'services' â€” extra in hypothesis
    7. 'rupees' â€” extra in hypothesis
    8. 'one' â€” extra in hypothesis
    9. 'thousand' â€” extra in hypothesis
    10. 'seven' â€” extra in hypothesis
    11. 'hundred' â€” extra in hypothesis
    12. 'rupees' â€” extra in hypothesis
    13. 'one' â€” extra in hypothesis
    14. 'thousand' â€” extra in hypothesis
    15. 'seven' â€” extra in hypothesis
    16. 'lagbhag' â€” extra in hypothesis
    17. 'rupees' â€” extra in hypothesis
    18. 'aur' â€” extra in hypothesis
    19. 'janna' â€” extra in hypothesis
    20. 'chahenge' â€” extra in hypothesis
    21. 'kya' â€” extra in hypothesis
    22. 'aap' â€” extra in hypothesis
    23. 'mujhse' â€” extra in hypothesis
    24. 'nano' â€” extra in hypothesis
    25. 'plan' â€” extra in hypothesis
    26. 'ya' â€” extra in hypothesis
    27. 'uske' â€” extra in hypothesis
    28. 'kisi' â€” extra in hypothesis
    29. 'specific' â€” extra in hypothesis
    30. 'feature' â€” extra in hypothesis
    31. 'main' â€” extra in hypothesis
    32. 'aapki' â€” extra in hypothesis
    33. 'madad' â€” extra in hypothesis
    34. 'ab' â€” extra in hypothesis
    35. 'kripaya' â€” extra in hypothesis
    36. 'spasht' â€” extra in hypothesis
    37. 'would' â€” extra in hypothesis
    38. 'you' â€” extra in hypothesis
    39. 'like' â€” extra in hypothesis
    40. 'more' â€” extra in hypothesis
    41. 'information' â€” extra in hypothesis
    42. 'on' â€” extra in hypothesis
    43. 'this' â€” extra in hypothesis
ðŸ [09f69426-e7e6-4f2a-a20a-75416d945306] completed at 19:13:37, took 76.06s
ðŸš€ [1bf3729b-c0a7-4f65-a846-88c8aa31a473] started at 19:13:37
ðŸŽ¯ Filtered 14 assistant utterances from 27 total utterances
ðŸŽ¯ Filtered 11 Agent utterances from 25 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/1bf3729b-c0a7-4f65-a846-88c8aa31a473/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/1bf3729b-c0a7-4f65-a846-88c8aa31a473/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 10 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/1bf3729b-c0a7-4f65-a846-88c8aa31a473/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/1bf3729b-c0a7-4f65-a846-88c8aa31a473/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0394
  Total GT NERs: 13
  Total Ref NERs: 22
  Unique GT NERs: 4
  Unique Ref NERs: 9
  Total Concerned GT NERs (PERSON/ORG): 9
  Total Concerned Ref NERs (PERSON/ORG): 13
  Unique Concerned GT NERs: 2
  Unique Concerned Ref NERs: 6
  Time taken: 0.216647 seconds

  Substitutions:
    1. 'related' -> 'returnrelated'
    2. 'related' -> 'returnrelated'
  Deletions:
    1. 'return' â€” missing in hypothesis
    2. 'return' â€” missing in hypothesis
  Insertions:
    1. 'hey' â€” extra in hypothesis
    2. 'i' â€” extra in hypothesis
    3. 'am' â€” extra in hypothesis
    4. 'simulating' â€” extra in hypothesis
    5. 'human' â€” extra in hypothesis
    6. 'transfer' â€” extra in hypothesis
ðŸ [1bf3729b-c0a7-4f65-a846-88c8aa31a473] completed at 19:14:05, took 27.87s
ðŸš€ [268dbd88-173b-41a1-8363-4a6ba62b9aae] started at 19:14:05
ðŸŽ¯ Filtered 21 assistant utterances from 35 total utterances
ðŸŽ¯ Filtered 14 Agent utterances from 24 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/268dbd88-173b-41a1-8363-4a6ba62b9aae/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/268dbd88-173b-41a1-8363-4a6ba62b9aae/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 28 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/268dbd88-173b-41a1-8363-4a6ba62b9aae/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/268dbd88-173b-41a1-8363-4a6ba62b9aae/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0561
  Total GT NERs: 21
  Total Ref NERs: 25
  Unique GT NERs: 7
  Unique Ref NERs: 7
  Total Concerned GT NERs (PERSON/ORG): 17
  Total Concerned Ref NERs (PERSON/ORG): 21
  Unique Concerned GT NERs: 4
  Unique Concerned Ref NERs: 4
  Time taken: 0.984322 seconds

  Substitutions:
    1. 'kovar' -> 'kondawar'
    2. 'have' -> 'youve'
    3. 'youd' -> 'were'
    4. 'specialized' -> 'obesityspecialized'
    5. 'map' -> 'roadmap'
    6. 'map' -> 'roadmap'
    7. 'back' -> 'moneyback'
    8. 'bye' -> 'goodbye'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. 'you' â€” missing in hypothesis
    3. 'now' â€” missing in hypothesis
    4. 'obesity' â€” missing in hypothesis
    5. 'road' â€” missing in hypothesis
    6. 'road' â€” missing in hypothesis
    7. 'goals' â€” missing in hypothesis
    8. '12' â€” missing in hypothesis
    9. 'money' â€” missing in hypothesis
    10. 'good' â€” missing in hypothesis
  Insertions:
    1. 'you' â€” extra in hypothesis
    2. 'let' â€” extra in hypothesis
    3. 'me' â€” extra in hypothesis
    4. 'explain' â€” extra in hypothesis
    5. 'great' â€” extra in hypothesis
    6. 'nano' â€” extra in hypothesis
    7. 'with' â€” extra in hypothesis
    8. 'the' â€” extra in hypothesis
    9. 'nano' â€” extra in hypothesis
    10. 'plan' â€” extra in hypothesis
ðŸ [268dbd88-173b-41a1-8363-4a6ba62b9aae] completed at 19:14:56, took 51.36s
ðŸš€ [332017b6-9f62-444d-a657-7b733bc727fc] started at 19:14:56
ðŸŽ¯ Filtered 21 assistant utterances from 41 total utterances
ðŸŽ¯ Filtered 16 Agent utterances from 28 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/332017b6-9f62-444d-a657-7b733bc727fc/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/332017b6-9f62-444d-a657-7b733bc727fc/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 43 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/332017b6-9f62-444d-a657-7b733bc727fc/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/332017b6-9f62-444d-a657-7b733bc727fc/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.1569
  Total GT NERs: 12
  Total Ref NERs: 14
  Unique GT NERs: 9
  Unique Ref NERs: 10
  Total Concerned GT NERs (PERSON/ORG): 8
  Total Concerned Ref NERs (PERSON/ORG): 10
  Unique Concerned GT NERs: 5
  Unique Concerned Ref NERs: 6
  Time taken: 0.315659 seconds

  Substitutions:
    1. '1024' -> 'twentyfour'
    2. 'with' -> 'you'd'
  Deletions:
    1. 'order' â€” missing in hypothesis
    2. 'i' â€” missing in hypothesis
    3. 'can' â€” missing in hypothesis
    4. 'assist' â€” missing in hypothesis
    5. 'you' â€” missing in hypothesis
  Insertions:
    1. 'hey' â€” extra in hypothesis
    2. 'please' â€” extra in hypothesis
    3. 'give' â€” extra in hypothesis
    4. 'me' â€” extra in hypothesis
    5. 'a' â€” extra in hypothesis
    6. 'moment' â€” extra in hypothesis
    7. 'to' â€” extra in hypothesis
    8. 'fetch' â€” extra in hypothesis
    9. 'your' â€” extra in hypothesis
    10. 'products' â€” extra in hypothesis
    11. 'however' â€” extra in hypothesis
    12. 'your' â€” extra in hypothesis
    13. 'items' â€” extra in hypothesis
    14. 'will' â€” extra in hypothesis
    15. 'arrive' â€” extra in hypothesis
    16. 'securely' â€” extra in hypothesis
    17. 'packed' â€” extra in hypothesis
    18. 'as' â€” extra in hypothesis
    19. 'per' â€” extra in hypothesis
    20. 'our' â€” extra in hypothesis
    21. 'standard' â€” extra in hypothesis
    22. 'procedures' â€” extra in hypothesis
    23. 'ten' â€” extra in hypothesis
    24. 'what' â€” extra in hypothesis
    25. 'else' â€” extra in hypothesis
    26. 'something' â€” extra in hypothesis
    27. 'and' â€” extra in hypothesis
    28. 'follow' â€” extra in hypothesis
    29. 'the' â€” extra in hypothesis
    30. 'i' â€” extra in hypothesis
    31. 'got' â€” extra in hypothesis
    32. 'it' â€” extra in hypothesis
    33. 'and' â€” extra in hypothesis
    34. 'following' â€” extra in hypothesis
    35. 'let' â€” extra in hypothesis
    36. 'me' â€” extra in hypothesis
ðŸ [332017b6-9f62-444d-a657-7b733bc727fc] completed at 19:15:22, took 25.44s
ðŸš€ [3502253e-259a-42d3-ab70-7aedabeb81fa] started at 19:15:22
ðŸŽ¯ Filtered 18 assistant utterances from 29 total utterances
ðŸŽ¯ Filtered 10 Agent utterances from 20 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/3502253e-259a-42d3-ab70-7aedabeb81fa/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/3502253e-259a-42d3-ab70-7aedabeb81fa/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 58 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/3502253e-259a-42d3-ab70-7aedabeb81fa/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/3502253e-259a-42d3-ab70-7aedabeb81fa/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.1016
  Total GT NERs: 40
  Total Ref NERs: 41
  Unique GT NERs: 26
  Unique Ref NERs: 24
  Total Concerned GT NERs (PERSON/ORG): 29
  Total Concerned Ref NERs (PERSON/ORG): 32
  Unique Concerned GT NERs: 15
  Unique Concerned Ref NERs: 16
  Time taken: 1.448065 seconds

  Substitutions:
    1. '3203' -> '32.03'
    2. 'front' -> 'upfront'
    3. '12' -> 'barah'
    4. 'term' -> 'longerterm'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. 'we' â€” missing in hypothesis
    3. 'backed' â€” missing in hypothesis
    4. 'up' â€” missing in hypothesis
    5. 'longer' â€” missing in hypothesis
  Insertions:
    1. 'great' â€” extra in hypothesis
    2. 'kya' â€” extra in hypothesis
    3. 'main' â€” extra in hypothesis
    4. 'aapko' â€” extra in hypothesis
    5. 'explain' â€” extra in hypothesis
    6. 'kar' â€” extra in hypothesis
    7. 'sakti' â€” extra in hypothesis
    8. 'hoon' â€” extra in hypothesis
    9. 'ki' â€” extra in hypothesis
    10. 'ye' â€” extra in hypothesis
    11. 'offerings' â€” extra in hypothesis
    12. 'aapki' â€” extra in hypothesis
    13. 'weight' â€” extra in hypothesis
    14. 'rupees' â€” extra in hypothesis
    15. 'great' â€” extra in hypothesis
    16. 'i'll' â€” extra in hypothesis
    17. 'send' â€” extra in hypothesis
    18. 'you' â€” extra in hypothesis
    19. 'the' â€” extra in hypothesis
    20. 'payment' â€” extra in hypothesis
    21. 'links' â€” extra in hypothesis
    22. 'on' â€” extra in hypothesis
    23. 'your' â€” extra in hypothesis
    24. 'registered' â€” extra in hypothesis
    25. 'mobile' â€” extra in hypothesis
    26. 'number' â€” extra in hypothesis
    27. 'via' â€” extra in hypothesis
    28. 'whatsapp' â€” extra in hypothesis
    29. 'if' â€” extra in hypothesis
    30. 'you' â€” extra in hypothesis
    31. 'have' â€” extra in hypothesis
    32. 'any' â€” extra in hypothesis
    33. 'more' â€” extra in hypothesis
    34. 'doubts' â€” extra in hypothesis
    35. 'in' â€” extra in hypothesis
    36. 'the' â€” extra in hypothesis
    37. 'future' â€” extra in hypothesis
    38. 'feel' â€” extra in hypothesis
    39. 'free' â€” extra in hypothesis
    40. 'to' â€” extra in hypothesis
    41. 'reach' â€” extra in hypothesis
    42. 'out' â€” extra in hypothesis
    43. 'goodbye' â€” extra in hypothesis
    44. 'and' â€” extra in hypothesis
    45. 'have' â€” extra in hypothesis
    46. 'a' â€” extra in hypothesis
    47. 'great' â€” extra in hypothesis
    48. 'day' â€” extra in hypothesis
    49. 'great' â€” extra in hypothesis
ðŸ [3502253e-259a-42d3-ab70-7aedabeb81fa] completed at 19:16:44, took 82.44s
ðŸš€ [429ac8a5-6f19-46b3-97bb-8e55feec389e] started at 19:16:44
ðŸŽ¯ Filtered 31 assistant utterances from 57 total utterances
ðŸŽ¯ Filtered 39 Agent utterances from 69 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/429ac8a5-6f19-46b3-97bb-8e55feec389e/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/429ac8a5-6f19-46b3-97bb-8e55feec389e/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 180 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/429ac8a5-6f19-46b3-97bb-8e55feec389e/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/429ac8a5-6f19-46b3-97bb-8e55feec389e/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.4390
  Total GT NERs: 19
  Total Ref NERs: 28
  Unique GT NERs: 11
  Unique Ref NERs: 16
  Total Concerned GT NERs (PERSON/ORG): 16
  Total Concerned Ref NERs (PERSON/ORG): 17
  Unique Concerned GT NERs: 8
  Unique Concerned Ref NERs: 8
  Time taken: 0.708353 seconds

  Substitutions:
    1. 'am' -> 'i'm'
    2. 'story' -> 'shtori'
    3. 'you' -> 'plus'
    4. 'referring' -> 'expected'
    5. 'story' -> 'with'
    6. 'story' -> 'shtori'
    7. 'cat' -> 'royalcat'
    8. 'ride' -> 'softride'
    9. 'not' -> 'don't'
    10. 'style' -> 'istyle'
    11. 'zaroor' -> 'your'
    12. 'main' -> 'delivery'
    13. 'hindi' -> 'partner'
    14. 'mein' -> 'find'
    15. 'bata' -> 'their'
    16. 'sakti' -> 'contact'
    17. 'hoon' -> 'on'
    18. 'aapka' -> 'the'
    19. 'i' -> 'my'
    20. 'style' -> 'orders'
    21. 'can' -> 'page'
    22. 'top' -> 'in'
    23. 'aaj' -> 'your'
    24. 'delivery' -> 'mintra'
    25. 'ke' -> 'app'
    26. 'liye' -> 'please'
    27. 'bahar' -> 'tell'
    28. 'hai' -> 'me'
    29. 'hi' -> 'is'
    30. 'how' -> 'anything'
    31. 'can' -> 'else'
    32. 'to' -> 'can'
    33. 'order' -> 'top'
    34. 'i' -> 'delivery'
    35. 'shared' -> 'today'
    36. 'status' -> 'expect'
    37. 'for' -> 'it'
    38. 'your' -> 'by'
    39. 'agnia' -> 'end'
    40. 'women' -> 'of'
    41. 'floral' -> 'day'
    42. 'print' -> 'please'
    43. 'mandarin' -> 'tell'
    44. 'collar' -> 'zarur'
    45. 'flared' -> 'main'
    46. 'sleeve' -> 'hindi'
    47. 'shirt' -> 'mein'
    48. 'style' -> 'bata'
    49. 'top' -> 'sakti'
    50. 'and' -> 'hoon'
    51. 'your' -> 'aapka'
    52. 'if' -> 'shuru'
    53. 'there' -> 'hua'
    54. 'anything' -> 'how'
    55. 'more' -> 'can'
    56. 'would' -> 'i'
    57. 'like' -> 'continue'
    58. 'know' -> 'help'
    59. 'please' -> 'you'
    60. 'let' -> 'with'
    61. 'me' -> 'your'
    62. 'know' -> 'order'
    63. 'is' -> 'there's'
    64. 'would' -> 'you'd'
  Deletions:
    1. 'i' â€” missing in hypothesis
    2. 'you' â€” missing in hypothesis
    3. 'royal' â€” missing in hypothesis
    4. 'soft' â€” missing in hypothesis
    5. 'do' â€” missing in hypothesis
    6. 'i' â€” missing in hypothesis
    7. 'continue' â€” missing in hypothesis
    8. 'there' â€” missing in hypothesis
    9. 'you' â€” missing in hypothesis
  Insertions:
    1. 'got' â€” extra in hypothesis
    2. 'it' â€” extra in hypothesis
    3. 'you' â€” extra in hypothesis
    4. 'please' â€” extra in hypothesis
    5. 'give' â€” extra in hypothesis
    6. 'me' â€” extra in hypothesis
    7. 'moment' â€” extra in hypothesis
    8. 'to' â€” extra in hypothesis
    9. 'fetch' â€” extra in hypothesis
    10. 'your' â€” extra in hypothesis
    11. 'products' â€” extra in hypothesis
    12. 'you're' â€” extra in hypothesis
    13. 'referring' â€” extra in hypothesis
    14. 'to' â€” extra in hypothesis
    15. 'the' â€” extra in hypothesis
    16. 'shtori' â€” extra in hypothesis
    17. 'shtori' â€” extra in hypothesis
    18. 'plus' â€” extra in hypothesis
    19. 'size' â€” extra in hypothesis
    20. 'reflective' â€” extra in hypothesis
    21. 'detail' â€” extra in hypothesis
    22. 'tshirt' â€” extra in hypothesis
    23. 'is' â€” extra in hypothesis
    24. 'be' â€” extra in hypothesis
    25. 'picked' â€” extra in hypothesis
    26. 'up' â€” extra in hypothesis
    27. 'by' â€” extra in hypothesis
    28. '7' â€” extra in hypothesis
    29. 'july' â€” extra in hypothesis
    30. 'subject' â€” extra in hypothesis
    31. 'quality' â€” extra in hypothesis
    32. 'check' â€” extra in hypothesis
    33. 'please' â€” extra in hypothesis
    34. 'tell' â€” extra in hypothesis
    35. 'me' â€” extra in hypothesis
    36. 'is' â€” extra in hypothesis
    37. 'there' â€” extra in hypothesis
    38. 'anything' â€” extra in hypothesis
    39. 'else' â€” extra in hypothesis
    40. 'i' â€” extra in hypothesis
    41. 'can' â€” extra in hypothesis
    42. 'help' â€” extra in hypothesis
    43. 'you' â€” extra in hypothesis
    44. 'is' â€” extra in hypothesis
    45. 'there' â€” extra in hypothesis
    46. 'please' â€” extra in hypothesis
    47. 'give' â€” extra in hypothesis
    48. 'me' â€” extra in hypothesis
    49. 'a' â€” extra in hypothesis
    50. 'moment' â€” extra in hypothesis
    51. 'to' â€” extra in hypothesis
    52. 'fetch' â€” extra in hypothesis
    53. 'your' â€” extra in hypothesis
    54. 'products' â€” extra in hypothesis
    55. 'day' â€” extra in hypothesis
    56. 'need' â€” extra in hypothesis
    57. 'reach' â€” extra in hypothesis
    58. 'istyle' â€” extra in hypothesis
    59. 'can' â€” extra in hypothesis
    60. 'out' â€” extra in hypothesis
    61. 'for' â€” extra in hypothesis
    62. 'delivery' â€” extra in hypothesis
    63. 'attempt' â€” extra in hypothesis
    64. 'started' â€” extra in hypothesis
    65. 'at' â€” extra in hypothesis
    66. '1044' â€” extra in hypothesis
    67. 'am' â€” extra in hypothesis
    68. 'you' â€” extra in hypothesis
    69. 'can' â€” extra in hypothesis
    70. 'aaj' â€” extra in hypothesis
    71. 'delivery' â€” extra in hypothesis
    72. 'ke' â€” extra in hypothesis
    73. 'liye' â€” extra in hypothesis
    74. 'bahar' â€” extra in hypothesis
    75. 'hai' â€” extra in hypothesis
    76. 'delivery' â€” extra in hypothesis
    77. 'ka' â€” extra in hypothesis
    78. 'prayas' â€” extra in hypothesis
    79. 'subah' â€” extra in hypothesis
    80. 'das' â€” extra in hypothesis
    81. 'bajkar' â€” extra in hypothesis
    82. 'chavalis' â€” extra in hypothesis
    83. 'minute' â€” extra in hypothesis
    84. 'par' â€” extra in hypothesis
    85. 'aaj' â€” extra in hypothesis
    86. 'ke' â€” extra in hypothesis
    87. Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/d9aa182c-b21e-4ad5-8138-18d0e9f69b84/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/d9aa182c-b21e-4ad5-8138-18d0e9f69b84/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 352 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/d9aa182c-b21e-4ad5-8138-18d0e9f69b84/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/d9aa182c-b21e-4ad5-8138-18d0e9f69b84/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.1368
  Total GT NERs: 19
  Total Ref NERs: 18
  Unique GT NERs: 17
  Unique Ref NERs: 17
  Total Concerned GT NERs (PERSON/ORG): 15
  Total Concerned Ref NERs (PERSON/ORG): 14
  Unique Concerned GT NERs: 13
  Unique Concerned Ref NERs: 13
  Time taken: 0.400108 seconds

  Substitutions:
    1. 'lakme' -> 'laamic'
    2. 'and' -> '&'
    3. 'right' -> 'alright'
    4. 'and' -> '&'
    5. 'love' -> 'lavender'
    6. 'antiaging' -> 'aging'
    7. 'retinol'âŒ [482181f8-15e2-4ced-8a9a-67facdd9c6fc] failed: Extra data: line 27 column 1 (char 458)
âŒ [482181f8-15e2-4ced-8a9a-67facdd9c6fc] failed: Extra data: line 27 column 1 (char 458)
ðŸš€ [5cdef144-9d6a-4100-9be6-8489f90fc466] started at 19:18:41
ðŸŽ¯ Filtered 19 assistant utterances from 35 total utterances
ðŸŽ¯ Filtered 14 Agent utterances from 24 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/5cdef144-9d6a-4100-9be6-8489f90fc466/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/5cdef144-9d6a-4100-9be6-8489f90fc466/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 38 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/5cdef144-9d6a-4100-9be6-8489f90fc466/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/5cdef144-9d6a-4100-9be6-8489f90fc466/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0803
  Total GT NERs: 24
  Total Ref NERs: 30
  Unique GT NERs: 14
  Unique Ref NERs: 15
  Total Concerned GT NERs (PERSON/ORG): 17
  Total Concerned Ref NERs (PERSON/ORG): 24
  Unique Concerned GT NERs: 7
  Unique Concerned Ref NERs: 11
  Time taken: 0.946893 seconds

  Substitutions:
    1. 'id' -> 'i'd'
    2. 'map' -> 'roadmap'
    3. '1799' -> 'nine'
    4. 'court' -> 'coach'
    5. 'onetime' -> 'time'
    6. 'he' -> 'the'
    7. 'rs' -> 'ninety'
    8. '1799' -> 'nine'
    9. 'have' -> 'we've'
    10. '499' -> 'nine'
    11. '1799' -> 'ninety'
    12. 'rupees' -> 'nine'
    13. 'up' -> 'rupees'
    14. 'front' -> 'upfront'
    15. 'ill' -> 'i'll'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. 'road' â€” missing in hypothesis
    3. 'we' â€” missing in hypothesis
  Insertions:
    1. 'i' â€” extra in hypothesis
    2. 'one' â€” extra in hypothesis
    3. 'thousand' â€” extra in hypothesis
    4. 'seven' â€” extra in hypothesis
    5. 'hundred' â€” extra in hypothesis
    6. 'ninety' â€” extra in hypothesis
    7. 'one' â€” extra in hypothesis
    8. 'rupees' â€” extra in hypothesis
    9. 'one' â€” extra in hypothesis
    10. 'thousand' â€” extra in hypothesis
    11. 'seven' â€” extra in hypothesis
    12. 'hundred' â€” extra in hypothesis
    13. 'we've' â€” extra in hypothesis
    14. 'four' â€” extra in hypothesis
    15. 'hundred' â€” extra in hypothesis
    16. 'ninety' â€” extra in hypothesis
    17. 'one' â€” extra in hypothesis
    18. 'thousand' â€” extra in hypothesis
    19. 'seven' â€” extra in hypothesis
    20. 'hundred' â€” extra in hypothesis
ðŸ [5cdef144-9d6a-4100-9be6-8489f90fc466] completed at 19:19:29, took 48.01s
ðŸš€ [5f4d919f-b1bc-4a3d-9d98-1f8279d51215] started at 19:19:29
ðŸŽ¯ Filtered 19 assistant utterances from 34 total utterances
ðŸŽ¯ Filtered 12 Agent utterances from 21 total utterances
Sending transcripts to LLM in parallel...
Saved canonical referSaved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/ec85480e-604c-4070-938f-b832e4904e9e/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/ec85480e-604c-4070-938f-b832e4904e9e/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
âŒ [ec85480e-604c-4070-938f-b832e4904e9e] failed: cannot access local variable 'ref_word' where it is not associated with a value
âŒ [ec85480e-604c-4070-938f-b832e4904e9e] failed: cannot access local variable 'ref_word' where it is not associated with a value
================================================================================
ðŸ“ˆ Processing Summary:
   Processed calls: 7
   Failed calls: 20

ðŸ·ï¸  All entity types encountered across all calls:
   - DATE/TIME
   - LANGUAGE
   - MONEY
   - ORG
   - ORGANIZATION
   - OTHER
   - PERSON
   - PRODUCT
   - TIME

ðŸ“Š Average WER across 7 calls: 0.0820
ðŸŒ Calculating Global WER...
   Total reference text length: 13090 characters
   Total hypothesis text length: 13484 characters
ðŸŽ¯ Global WER (entire system performance): 0.1089

ðŸ“‹ Generating summary report...
âœ… Summary report saved to: /Users/adyasrivastava/wer/wer+jiwer/global_wer_summary_gpt_lib.csv
ðŸŒ Global WER report saved to: /Users/adyasrivastava/wer/wer+jiwer/global_wer_report_gpt_lib.json

â±ï¸  Total processing time: 1379.04 seconds
ðŸŽ‰ Processing complete!
extra in hypothesis
    7. 'ninety' â€” extra in hypothesis
    8. 'all' â€” extra in hypothesis
    9. 'in' â€” extra in hypothesis
ðŸ [5f4d919f-b1bc-4a3d-9d98-1f8279d51215] completed at 19:20:17, took 47.36s
ðŸš€ [750dfc05-c2c4-4937-a85d-46f597dc9880] started at 19:20:17
ðŸŽ¯ Filtered 14 assistant utterances from 24 total utterances
ðŸŽ¯ Filtered 12 Agent utterances from 22 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/750dfc05-c2c4-4937-a85d-46f597dc9880/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/750dfc05-c2c4-4937-a85d-46f597dc9880/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 7 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/750dfc05-c2c4-4937-a85d-46f597dc9880/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/750dfc05-c2c4-4937-a85d-46f597dc9880/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0147
  Total GT NERs: 29
  Total Ref NERs: 26
  Unique GT NERs: 22
  Unique Ref NERs: 18
  Total Concerned GT NERs (PERSON/ORG): 18
  Total Concerned Ref NERs (PERSON/ORG): 18
  Unique Concerned GT NERs: 11
  Unique Concerned Ref NERs: 11
  Time taken: 0.858103 seconds

  Substitutions:
    1. 'id' -> 'i'd'
    2. 'rs' -> 'rupees'
    3. 'rs' -> 'rupees'
    4. 'ill' -> 'i'll'
    5. 'ill' -> 'i'll'
  Deletions:
    1. 'now' â€” missing in hypothesis
  Insertions:
    1. 'great' â€” extra in hypothesis
ðŸ [750dfc05-c2c4-4937-a85d-46f597dc9880] completed at 19:21:05, took 48.08s
ðŸš€ [79e02e46-ea93-4669-9dc1-6c4339dcc6ba] started at 19:21:05
ðŸŽ¯ Filtered 15 assistant utterances from 30 total utterances
ðŸŽ¯ Filtered 12 Agent utterances from 23 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/79e02e46-ea93-4669-9dc1-6c4339dcc6ba/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/79e02e46-ea93-4669-9dc1-6c4339dcc6ba/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 19 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/79e02e46-ea93-4669-9dc1-6c4339dcc6ba/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/79e02e46-ea93-4669-9dc1-6c4339dcc6ba/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0693
  Total GT NERs: 15
  Total Ref NERs: 16
  Unique GT NERs: 11
  Unique Ref NERs: 13
  Total Concerned GT NERs (PERSON/ORG): 11
  Total Concerned Ref NERs (PERSON/ORG): 11
  Unique Concerned GT NERs: 7
  Unique Concerned Ref NERs: 8
  Time taken: 0.283081 seconds

  Substitutions:
    1. '505' -> 'five'
    2. 'n' -> 'and'
    3. 'sasafers' -> 'fars'
    4. 'unrl' -> 'rl'
  Deletions:
  Insertions:
    1. 'hey' â€” extra in hypothesis
    2. 'five' â€” extra in hypothesis
    3. 'is' â€” extra in hypothesis
    4. 'this' â€” extra in hypothesis
    5. 'the' â€” extra in hypothesis
    6. 'item' â€” extra in hypothesis
    7. 'you' â€” extra in hypothesis
    8. 'created' â€” extra in hypothesis
    9. 'a' â€” extra in hypothesis
    10. 'return' â€” extra in hypothesis
    11. 'for' â€” extra in hypothesis
    12. 'could' â€” extra in hypothesis
    13. 'you' â€” extra in hypothesis
    14. 'sasa' â€” extra in hypothesis
    15. 'un' â€” extra in hypothesis
ðŸ [79e02e46-ea93-4669-9dc1-6c4339dcc6ba] completed at 19:21:35, took 30.03s
ðŸš€ [7bbd5f06-2ac0-4227-be76-4ce7ef7cb567] started at 19:21:35
ðŸŽ¯ Filtered 15 assistant utterances from 25 total utterances
ðŸŽ¯ Filtered 15 Agent utterances from 26 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/7bbd5f06-2ac0-4227-be76-4ce7ef7cb567/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/7bbd5f06-2ac0-4227-be76-4ce7ef7cb567/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 36 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/7bbd5f06-2ac0-4227-be76-4ce7ef7cb567/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/7bbd5f06-2ac0-4227-be76-4ce7ef7cb567/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0730
  Total GT NERs: 25
  Total Ref NERs: 26
  Unique GT NERs: 14
  Unique Ref NERs: 15
  Total Concerned GT NERs (PERSON/ORG): 18
  Total Concerned Ref NERs (PERSON/ORG): 18
  Unique Concerned GT NERs: 8
  Unique Concerned Ref NERs: 8
  Time taken: 0.923555 seconds

  Substitutions:
    1. 'id' -> 'i'd'
    2. 'map' -> 'roadmap'
    3. '1799' -> 'nine'
    4. 'im' -> 'i'm'
    5. '1799' -> 'ninety'
    6. 'up' -> 'nine'
    7. 'front' -> 'upfront'
    8. '499' -> 'nine'
    9. '1399' -> 'nine'
    10. 'ill' -> 'i'll'
    11. 'ill' -> 'i'll'
    12. 'ill' -> 'i'll'
    13. 'bye' -> 'goodbye'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. 'we' â€” missing in hypothesis
    3. 'road' â€” missing in hypothesis
    4. 'good' â€” missing in hypothesis
  Insertions:
    1. 'with' â€” extra in hypothesis
    2. 'nidhi' â€” extra in hypothesis
    3. 'one' â€” extra in hypothesis
    4. 'thousand' â€” extra in hypothesis
    5. 'seven' â€” extra in hypothesis
    6. 'hundred' â€” extra in hypothesis
    7. 'ninety' â€” extra in hypothesis
    8. 'one' â€” extra in hypothesis
    9. 'thousand' â€” extra in hypothesis
    10. 'seven' â€” extra in hypothesis
    11. 'hundred' â€” extra in hypothesis
    12. 'four' â€” extra in hypothesis
    13. 'hundred' â€” extra in hypothesis
    14. 'ninety' â€” extra in hypothesis
    15. 'one' â€” extra in hypothesis
    16. 'thousand' â€” extra in hypothesis
    17. 'three' â€” extra in hypothesis
    18. 'hundred' â€” extra in hypothesis
    19. 'ninety' â€” extra in hypothesis
ðŸ [7bbd5f06-2ac0-4227-be76-4ce7ef7cb567] completed at 19:22:18, took 43.29s
ðŸš€ [7fd6b5f9-8b11-4085-b864-a16f92504e53] started at 19:22:18
ðŸŽ¯ Filtered 23 assistant utterances from 44 total utterances
ðŸŽ¯ Filtered 15 Agent utterances from 29 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/7fd6b5f9-8b11-4085-b864-a16f92504e53/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/7fd6b5f9-8b11-4085-b864-a16f92504e53/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 73 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/7fd6b5f9-8b11-4085-b864-a16f92504e53/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/7fd6b5f9-8b11-4085-b864-a16f92504e53/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.1155
  Total GT NERs: 32
  Total Ref NERs: 19
  Unique GT NERs: 15
  Unique Ref NERs: 8
  Total Concerned GT NERs (PERSON/ORG): 23
  Total Concerned Ref NERs (PERSON/ORG): 18
  Unique Concerned GT NERs: 9
  Unique Concerned Ref NERs: 7
  Time taken: 1.559108 seconds

  Substitutions:
    1. 'map' -> 'roadmap'
    2. '1799' -> 'ninetynine'
    3. 'burning' -> 'fatburning'
  Deletions:
    1. 'we' â€” missing in hypothesis
    2. 'we' â€” missing in hypothesis
    3. 'road' â€” missing in hypothesis
    4. 'rich' â€” missing in hypothesis
    5. 'fat' â€” missing in hypothesis
    6. 'the' â€” missing in hypothesis
    7. 'nano' â€” missing in hypothesis
    8. 'plan' â€” missing in hypothesis
    9. 'offers' â€” missing in hypothesis
    10. 'flexibility' â€” missing in hypothesis
    11. 'with' â€” missing in hypothesis
    12. 'two' â€” missing in hypothesis
    13. 'payment' â€” missing in hypothesis
    14. 'options' â€” missing in hypothesis
    15. 'a' â€” missing in hypothesis
    16. 'partial' â€” missing in hypothesis
    17. 'payment' â€” missing in hypothesis
    18. 'of' â€” missing in hypothesis
    19. 'rupees' â€” missing in hypothesis
    20. '499' â€” missing in hypothesis
    21. 'now' â€” missing in hypothesis
    22. 'and' â€” missing in hypothesis
    23. 'the' â€” missing in hypothesis
    24. 'remaining' â€” missing in hypothesis
    25. 'rupees' â€” missing in hypothesis
    26. '1399' â€” missing in hypothesis
    27. 'at' â€” missing in hypothesis
    28. 'the' â€” missing in hypothesis
    29. 'time' â€” missing in hypothesis
    30. 'of' â€” missing in hypothesis
    31. 'blood' â€” missing in hypothesis
    32. 'sample' â€” missing in hypothesis
    33. 'collection' â€” missing in hypothesis
    34. 'or' â€” missing in hypothesis
    35. 'a' â€” missing in hypothesis
    36. 'full' â€” missing in hypothesis
    37. 'payment' â€” missing in hypothesis
    38. 'of' â€” missing in hypothesis
    39. 'rupees' â€” missing in hypothesis
    40. '1799' â€” missing in hypothesis
    41. 'up' â€” missing in hypothesis
    42. 'front' â€” missing in hypothesis
    43. 'ill' â€” missing in hypothesis
    44. 'send' â€” missing in hypothesis
    45. 'you' â€” missing in hypothesis
    46. 'the' â€” missing in hypothesis
    47. 'payment' â€” missing in hypothesis
    48. 'links' â€” missing in hypothesis
    49. 'on' â€” missing in hypothesis
    50. 'your' â€” missing in hypothesis
    51. 'registered' â€” missing in hypothesis
    52. 'mobile' â€” missing in hypothesis
  Insertions:
    1. 'elevatenow' â€” extra in hypothesis
    2. 'am' â€” extra in hypothesis
    3. 'i' â€” extra in hypothesis
    4. 'speaking' â€” extra in hypothesis
    5. 'with' â€” extra in hypothesis
    6. 'bijal' â€” extra in hypothesis
    7. 'roliya' â€” extra in hypothesis
    8. 'based' â€” extra in hypothesis
    9. 'on' â€” extra in hypothesis
    10. 'your' â€” extra in hypothesis
    11. 'bmi' â€” extra in hypothesis
    12. 'of' â€” extra in hypothesis
    13. '3413' â€” extra in hypothesis
    14. 'experience' â€” extra in hypothesis
    15. 'one' â€” extra in hypothesis
    16. 'thousand' â€” extra in hypothesis
    17. 'seven' â€” extra in hypothesis
    18. 'hundred' â€” extra in hypothesis
ðŸ [7fd6b5f9-8b11-4085-b864-a16f92504e53] completed at 19:23:13, took 55.48s
ðŸš€ [8daee0cc-cbda-4cdf-b8ed-f120e3329138] started at 19:23:13
ðŸŽ¯ Filtered 18 assistant utterances from 33 total utterances
ðŸŽ¯ Filtered 17 Agent utterances from 32 total utterances
Sending transcripts to LLM in parallel...
âŒ [8daee0cc-cbda-4cdf-b8ed-f120e3329138] failed: Extra data: line 27 column 1 (char 467)
âŒ [8daee0cc-cbda-4cdf-b8ed-f120e3329138] failed: Extra data: line 27 column 1 (char 467)
ðŸš€ [99d176ec-e484-4937-ae0b-9d6d2d7cb5c5] started at 19:23:56
ðŸŽ¯ Filtered 17 assistant utterances from 31 total utterances
ðŸŽ¯ Filtered 12 Agent utterances from 23 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/99d176ec-e484-4937-ae0b-9d6d2d7cb5c5/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/99d176ec-e484-4937-ae0b-9d6d2d7cb5c5/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 13 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/99d176ec-e484-4937-ae0b-9d6d2d7cb5c5/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/99d176ec-e484-4937-ae0b-9d6d2d7cb5c5/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0349
  Total GT NERs: 13
  Total Ref NERs: 9
  Unique GT NERs: 7
  Unique Ref NERs: 6
  Total Concerned GT NERs (PERSON/ORG): 6
  Total Concerned Ref NERs (PERSON/ORG): 6
  Unique Concerned GT NERs: 3
  Unique Concerned Ref NERs: 4
  Time taken: 0.522097 seconds

  Substitutions:
    1. 'right' -> 'alright'
    2. 'neck' -> 'roundneck'
    3. 'right' -> 'alright'
  Deletions:
    1. 'all' â€” missing in hypothesis
    2. 'you' â€” missing in hypothesis
    3. 'round' â€” missing in hypothesis
    4. 'all' â€” missing in hypothesis
  Insertions:
    1. 'hey' â€” extra in hypothesis
    2. 'h' â€” extra in hypothesis
    3. 'and' â€” extra in hypothesis
    4. 'i' â€” extra in hypothesis
    5. 'h' â€” extra in hypothesis
    6. 'and' â€” extra in hypothesis
ðŸ [99d176ec-e484-4937-ae0b-9d6d2d7cb5c5] completed at 19:24:21, took 25.41s
ðŸš€ [a26f3d38-ed43-4289-8d34-9ee376fb779d] started at 19:24:21
ðŸŽ¯ Filtered 21 assistant utterances from 41 total utterances
ðŸŽ¯ Filtered 37 Agent utterances from 71 total utterances
Sending transcripts to LLM in parallel...
âŒ [a26f3d38-ed43-4289-8d34-9ee376fb779d] failed: Extra data: line 27 column 1 (char 458)
âŒ [a26f3d38-ed43-4289-8d34-9ee376fb779d] failed: Extra data: line 27 column 1 (char 458)
ðŸš€ [b94c0a58-b1c3-4bc8-ba02-0848b0a2af8f] started at 19:25:28
ðŸŽ¯ Filtered 21 assistant utterances from 35 total utterances
ðŸŽ¯ Filtered 12 Agent utterances from 23 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/b94c0a58-b1c3-4bc8-ba02-0848b0a2af8f/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/b94c0a58-b1c3-4bc8-ba02-0848b0a2af8f/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 42 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/b94c0a58-b1c3-4bc8-ba02-0848b0a2af8f/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/b94c0a58-b1c3-4bc8-ba02-0848b0a2af8f/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0782
  Total GT NERs: 25
  Total Ref NERs: 29
  Unique GT NERs: 12
  Unique Ref NERs: 13
  Total Concerned GT NERs (PERSON/ORG): 19
  Total Concerned Ref NERs (PERSON/ORG): 26
  Unique Concerned GT NERs: 6
  Unique Concerned Ref NERs: 10
  Time taken: 1.120161 seconds

  Substitutions:
    1. 'id' -> 'i'd'
    2. '45' -> 'fortyfive'
    3. 'then' -> 'the'
    4. 'right' -> 'alright'
    5. 'im' -> 'i'm'
    6. 'im' -> 'i'm'
    7. 'im' -> 'i'm'
    8. 'rs' -> 'hundred'
    9. '1799' -> 'ninetynine'
    10. 'right' -> 'alright'
  Deletions:
    1. 'hello' â€” missing in hypothesis
    2. 'this' â€” missing in hypothesis
    3. 'is' â€” missing in hypothesis
    4. 'priya' â€” missing in hypothesis
    5. 'from' â€” missing in hypothesis
    6. 'elevate' â€” missing in hypothesis
    7. 'now' â€” missing in hypothesis
    8. 'am' â€” missing in hypothesis
    9. 'i' â€” missing in hypothesis
    10. 'speaking' â€” missing in hypothesis
    11. 'with' â€” missing in hypothesis
    12. 'nikita' â€” missing in hypothesis
    13. 'all' â€” missing in hypothesis
    14. 'all' â€” missing in hypothesis
  Insertions:
    1. 'hello' â€” extra in hypothesis
    2. 'this' â€” extra in hypothesis
    3. 'is' â€” extra in hypothesis
    4. 'priya' â€” extra in hypothesis
    5. 'from' â€” extra in hypothesis
    6. 'elevatenow' â€” extra in hypothesis
    7. 'am' â€” extra in hypothesis
    8. 'i' â€” extra in hypothesis
    9. 'speaking' â€” extra in hypothesis
    10. 'with' â€” extra in hypothesis
    11. 'niketa' â€” extra in hypothesis
    12. 'to' â€” extra in hypothesis
    13. 'be' â€” extra in hypothesis
    14. 'rupees' â€” extra in hypothesis
    15. 'one' â€” extra in hypothesis
    16. 'thousand' â€” extra in hypothesis
    17. 'seven' â€” extra in hypothesis
    18. 'you' â€” extra in hypothesis
ðŸ [b94c0a58-b1c3-4bc8-ba02-0848b0a2af8f] completed at 19:26:17, took 49.35s
ðŸš€ [c5f1aee1-8170-4c1b-93e0-1f8366882689] started at 19:26:17
ðŸŽ¯ Filtered 13 assistant utterances from 24 total utterances
ðŸŽ¯ Filtered 40 Agent utterances from 75 total utterances
Sending transcripts to LLM in parallel...
âŒ [c5f1aee1-8170-4c1b-93e0-1f8366882689] failed: Extra data: line 26 column 1 (char 466)
âŒ [c5f1aee1-8170-4c1b-93e0-1f8366882689] failed: Extra data: line 26 column 1 (char 466)
ðŸš€ [d24a5dc2-ac06-4f13-bbd1-5ec010d8d27c] started at 19:26:53
ðŸŽ¯ Filtered 18 assistant utterances from 33 total utterances
ðŸŽ¯ Filtered 14 Agent utterances from 25 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/d24a5dc2-ac06-4f13-bbd1-5ec010d8d27c/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/d24a5dc2-ac06-4f13-bbd1-5ec010d8d27c/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 16 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/d24a5dc2-ac06-4f13-bbd1-5ec010d8d27c/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/d24a5dc2-ac06-4f13-bbd1-5ec010d8d27c/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0290
  Total GT NERs: 32
  Total Ref NERs: 30
  Unique GT NERs: 21
  Unique Ref NERs: 19
  Total Concerned GT NERs (PERSON/ORG): 24
  Total Concerned Ref NERs (PERSON/ORG): 22
  Unique Concerned GT NERs: 13
  Unique Concerned Ref NERs: 11
  Time taken: 1.161615 seconds

  Substitutions:
    1. 'rs' -> 'hundred'
    2. '1799' -> 'ninetynine'
    3. 'rs' -> 'six'
    4. '6000' -> 'thousand'
    5. 'anymore' -> 'more'
    6. 'whenever' -> 'you'
    7. 'you' -> 'whenever'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. 'and' â€” missing in hypothesis
  Insertions:
    1. 'were' â€” extra in hypothesis
    2. 'rupees' â€” extra in hypothesis
    3. 'one' â€” extra in hypothesis
    4. 'thousand' â€” extra in hypothesis
    5. 'seven' â€” extra in hypothesis
    6. 'rupees' â€” extra in hypothesis
    7. 'any' â€” extra in hypothesis
ðŸ [d24a5dc2-ac06-4f13-bbd1-5ec010d8d27c] completed at 19:27:47, took 53.73s
ðŸš€ [d521ea56-2e7b-4908-8cca-acf4a0f89337] started at 19:27:47
ðŸŽ¯ Filtered 16 assistant utterances from 29 total utterances
ðŸŽ¯ Filtered 11 Agent utterances from 20 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/d521ea56-2e7b-4908-8cca-acf4a0f89337/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/d521ea56-2e7b-4908-8cca-acf4a0f89337/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 33 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/d521ea56-2e7b-4908-8cca-acf4a0f89337/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/d521ea56-2e7b-4908-8cca-acf4a0f89337/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0695
  Total GT NERs: 27
  Total Ref NERs: 34
  Unique GT NERs: 18
  Unique Ref NERs: 25
  Total Concerned GT NERs (PERSON/ORG): 20
  Total Concerned Ref NERs (PERSON/ORG): 21
  Unique Concerned GT NERs: 12
  Unique Concerned Ref NERs: 13
  Time taken: 0.905858 seconds

  Substitutions:
    1. '290' -> 'zero'
    2. 'a' -> 'our'
    3. '1799' -> 'nine'
    4. '6000' -> 'thousand'
    5. '5000' -> 'thousand'
    6. '200' -> 'hundred'
    7. 'map' -> 'roadmap'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. '1' â€” missing in hypothesis
    3. 'backed' â€” missing in hypothesis
    4. 'road' â€” missing in hypothesis
  Insertions:
    1. 'twenty' â€” extra in hypothesis
    2. 'nine' â€” extra in hypothesis
    3. 'point' â€” extra in hypothesis
    4. 'let' â€” extra in hypothesis
    5. 'me' â€” extra in hypothesis
    6. 'give' â€” extra in hypothesis
    7. 'you' â€” extra in hypothesis
    8. 'a' â€” extra in hypothesis
    9. 'quick' â€” extra in hypothesis
    10. 'overview' â€” extra in hypothesis
    11. 'of' â€” extra in hypothesis
    12. 'our' â€” extra in hypothesis
    13. 'nano' â€” extra in hypothesis
    14. 'plan' â€” extra in hypothesis
    15. 'one' â€” extra in hypothesis
    16. 'thousand' â€” extra in hypothesis
    17. 'seven' â€” extra in hypothesis
    18. 'hundred' â€” extra in hypothesis
    19. 'ninety' â€” extra in hypothesis
    20. 'six' â€” extra in hypothesis
    21. 'five' â€” extra in hypothesis
    22. 'two' â€” extra in hypothesis
ðŸ [d521ea56-2e7b-4908-8cca-acf4a0f89337] completed at 19:28:38, took 50.81s
ðŸš€ [d7c521ce-dbcb-4c23-a776-66b38d8127b4] started at 19:28:38
ðŸŽ¯ Filtered 14 assistant utterances from 22 total utterances
ðŸŽ¯ Filtered 14 Agent utterances from 23 total utterances
Sending transcripts to LLM in parallel...
âŒ [d7c521ce-dbcb-4c23-a776-66b38d8127b4] failed: Extra data: line 25 column 2 (char 465)
âŒ [d7c521ce-dbcb-4c23-a776-66b38d8127b4] failed: Extra data: line 25 column 2 (char 465)
ðŸš€ [d9aa182c-b21e-4ad5-8138-18d0e9f69b84] started at 19:29:16
ðŸŽ¯ Filtered 15 assistant utterances from 26 total utterances
ðŸŽ¯ Filtered 13 Agent utterances from 23 total utterances
Sending transcripts to LLM in parallel...
âŒ [d9aa182c-b21e-4ad5-8138-18d0e9f69b84] failed: Extra data: line 26 column 1 (char 466)
âŒ [d9aa182c-b21e-4ad5-8138-18d0e9f69b84] failed: Extra data: line 26 column 1 (char 466)
ðŸš€ [e69e62f6-954a-4d0a-9989-2a2d562f66fe] started at 19:30:10
ðŸŽ¯ Filtered 14 assistant utterances from 27 total utterances
ðŸŽ¯ Filtered 12 Agent utterances from 22 total utterances
Sending transcripts to LLM in parallel...
âŒ [e69e62f6-954a-4d0a-9989-2a2d562f66fe] failed: Extra data: line 27 column 1 (char 458)
âŒ [e69e62f6-954a-4d0a-9989-2a2d562f66fe] failed: Extra data: line 27 column 1 (char 458)
ðŸš€ [eacbcb92-6172-41f7-b2a9-0c4df5a3a597] started at 19:30:56
ðŸŽ¯ Filtered 22 assistant utterances from 38 total utterances
ðŸŽ¯ Filtered 19 Agent utterances from 31 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/eacbcb92-6172-41f7-b2a9-0c4df5a3a597/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/eacbcb92-6172-41f7-b2a9-0c4df5a3a597/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 29 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/eacbcb92-6172-41f7-b2a9-0c4df5a3a597/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/eacbcb92-6172-41f7-b2a9-0c4df5a3a597/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.0617
  Total GT NERs: 17
  Total Ref NERs: 22
  Unique GT NERs: 11
  Unique Ref NERs: 15
  Total Concerned GT NERs (PERSON/ORG): 13
  Total Concerned Ref NERs (PERSON/ORG): 15
  Unique Concerned GT NERs: 8
  Unique Concerned Ref NERs: 9
  Time taken: 0.718512 seconds

  Substitutions:
    1. 'rise' -> 'midrise'
    2. 'and' -> '&'
    3. 'rise' -> 'midrise'
    4. 'rise' -> 'midrise'
    5. 'right' -> 'alright'
    6. 'and' -> '&'
    7. 'jack' -> 'itemsâ€”jack'
    8. 'and' -> '&'
    9. 'rice' -> 'midrise'
    10. 'rice' -> 'midrise'
    11. '25th' -> '25'
    12. 'your' -> 'smsâ€”your'
  Deletions:
    1. 'english' â€” missing in hypothesis
    2. 'please' â€” missing in hypothesis
    3. 'fit' â€” missing in hypothesis
    4. 'mid' â€” missing in hypothesis
    5. 'fit' â€” missing in hypothesis
    6. 'fit' â€” missing in hypothesis
    7. 'fit' â€” missing in hypothesis
    8. 'fit' â€” missing in hypothesis
    9. 'mid' â€” missing in hypothesis
    10. 'fit' â€” missing in hypothesis
    11. 'fit' â€” missing in hypothesis
    12. 'mid' â€” missing in hypothesis
    13. 'all' â€” missing in hypothesis
    14. 'items' â€” missing in hypothesis
    15. 'mid' â€” missing in hypothesis
    16. 'mid' â€” missing in hypothesis
    17. 'sms' â€” missing in hypothesis
  Insertions:
ðŸ [eacbcb92-6172-41f7-b2a9-0c4df5a3a597] completed at 19:31:49, took 53.36s
ðŸš€ [ec85480e-604c-4070-938f-b832e4904e9e] started at 19:31:49
ðŸŽ¯ Filtered 18 assistant utterances from 30 total utterances
ðŸŽ¯ Filtered 14 Agent utterances from 25 total utterances
Sending transcripts to LLM in parallel...
Saved canonical reference -> /Users/adyasrivastava/wer/wer+jiwer/calls/ec85480e-604c-4070-938f-b832e4904e9e/output/canon_ref_transcript_gpt_lib.json
Saved canonical hypothesis -> /Users/adyasrivastava/wer/wer+jiwer/calls/ec85480e-604c-4070-938f-b832e4904e9e/output/canon_gt_transcript_gpt_lib.json
Loading canonical transcripts for WER calculation...
Logged 43 mismatches and measures to /Users/adyasrivastava/wer/wer+jiwer/calls/ec85480e-604c-4070-938f-b832e4904e9e/output/wer_mismatches_gpt_lib.json
Saved comprehensive results -> /Users/adyasrivastava/wer/wer+jiwer/calls/ec85480e-604c-4070-938f-b832e4904e9e/output/wer+eer_gpt_lib.json

Results summary:
  WER: 0.1002
  Total GT NERs: 26
  Total Ref NERs: 20
  Unique GT NERs: 15
  Unique Ref NERs: 11
  Total Concerned GT NERs (PERSON/ORG): 14
  Total Concerned Ref NERs (PERSON/ORG): 10
  Unique Concerned GT NERs: 6
  Unique Concerned Ref NERs: 4
  Time taken: 0.742872 seconds

  Substitutions:
    1. 'the' -> 'their'
    2. '1799' -> 'nine'
    3. '6000' -> 'thousand'
    4. '499' -> 'nine'
    5. '1399' -> 'nine'
    6. '1898' -> 'eight'
    7. '1799' -> 'ninety'
    8. 'up' -> 'nine'
    9. 'front' -> 'upfront'
  Deletions:
    1. 'now' â€” missing in hypothesis
    2. 'now' â€” missing in hypothesis
  Insertions:
    1. 'i' â€” extra in hypothesis
    2. 'great' â€” extra in hypothesis
    3. 'absolutely' â€” extra in hypothesis
    4. 'one' â€” extra in hypothesis
    5. 'thousand' â€” extra in hypothesis
    6. 'seven' â€” extra in hypothesis
    7. 'hundred' â€” extra in hypothesis
    8. 'ninety' â€” extra in hypothesis
    9. 'six' â€” extra in hypothesis
    10. 'the' â€” extra in hypothesis
    11. 'payment' â€” extra in hypothesis
    12. 'options' â€” extra in hypothesis
    13. 'you' â€” extra in hypothesis
    14. 'have' â€” extra in hypothesis
    15. 'four' â€” extra in hypothesis
    16. 'hundred' â€” extra in hypothesis
    17. 'ninety' â€” extra in hypothesis
    18. 'one' â€” extra in hypothesis
    19. 'thousand' â€” extra in hypothesis
    20. 'three' â€” extra in hypothesis
    21. 'hundred' â€” extra in hypothesis
    22. 'ninety' â€” extra in hypothesis
    23. 'one' â€” extra in hypothesis
    24. 'thousand' â€” extra in hypothesis
    25. 'eight' â€” extra in hypothesis
    26. 'hundred' â€” extra in hypothesis
    27. 'ninety' â€” extra in hypothesis
    28. 'one' â€” extra in hypothesis
    29. 'thousand' â€” extra in hypothesis
    30. 'seven' â€” extra in hypothesis
    31. 'hundred' â€” extra in hypothesis
    32. 'great' â€” extra in hypothesis
ðŸ [ec85480e-604c-4070-938f-b832e4904e9e] completed at 19:32:34, took 44.76s
================================================================================
ðŸ“ˆ Processing Summary:
   Processed calls: 19
   Failed calls: 8

ðŸ·ï¸  All entity types encountered across all calls:
   - CARDINAL
   - DATE/TIME
   - EVENT
   - LANGUAGE
   - LOCATION/GPE
   - MONEY
   - ORG
   - ORGANIZATION
   - OTHER
   - PERSON
   - PRODUCT
   - TIME

ðŸ“Š Average WER across 19 calls: 0.0986
ðŸŒ Calculating Global WER...
   Total reference text length: 49110 characters
   Total hypothesis text length: 51192 characters
ðŸŽ¯ Global WER (entire system performance): 0.1173

ðŸ“‹ Generating summary report...
âœ… Summary report saved to: /Users/adyasrivastava/wer/wer+jiwer/global_wer_summary_gpt_lib.csv
ðŸŒ Global WER report saved to: /Users/adyasrivastava/wer/wer+jiwer/global_wer_report_gpt_lib.json

â±ï¸  Total processing time: 1281.00 seconds
ðŸŽ‰ Processing complete!
